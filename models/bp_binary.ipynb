{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import config\n",
    "import seaborn as sn\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from multi_scale_unet import UNET\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tvtransforms\n",
    "import time\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import metrics as smpmetrics\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from meter import AverageValueMeter\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import neptune.new as neptune\n",
    "from neptune.new.types import File\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/jmt1423/coastal-segmentation/e/COAS-25\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"jmt1423/coastal-segmentation\",\n",
    "    source_files = ['./*.ipynb', './*.py'],\n",
    "    api_token=config.NEPTUNE_API_TOKEN,\n",
    ")  # your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "ENCODER = \"resnet18\"\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'sigmoid'\n",
    "BATCH_SIZE = 1\n",
    "MODEL_NAME = 'unet'\n",
    "LEARNING_RATE = 0.00001\n",
    "loss = smp.losses.DiceLoss(mode='binary')\n",
    "LOSS_STR = 'Dice Loss'\n",
    "EPOCHS = 150\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# optimizer parameters\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "OPTIM_NAME = 'AdamW'\n",
    "\n",
    "# image parameters\n",
    "MIN_HEIGHT = 32\n",
    "MIN_WIDTH = 512\n",
    "TRAIN_MIN_HEIGHT = 32\n",
    "TRAIN_MIN_WIDTH = 512\n",
    "\n",
    "binary_result_paths = [\n",
    "    'binary_results/0.png',\n",
    "    'binary_results/1.png',\n",
    "    'binary_results/2.png',\n",
    "    'binary_results/3.png',\n",
    "    'binary_results/4.png',\n",
    "    'binary_results/5.png',\n",
    "    'binary_results/6.png',\n",
    "    'binary_results/7.png',\n",
    "    'binary_results/8.png',\n",
    "    'binary_results/9.png',\n",
    "    'binary_results/10.png',\n",
    "    'binary_results/11.png',\n",
    "    'binary_results/12.png',\n",
    "    'binary_results/13.png',\n",
    "    'binary_results/14.png',\n",
    "    'binary_results/15.png',\n",
    "    'binary_results/pred_0.png',\n",
    "    'binary_results/pred_1.png',\n",
    "    'binary_results/pred_2.png',\n",
    "    'binary_results/pred_3.png',\n",
    "    'binary_results/pred_4.png',\n",
    "    'binary_results/pred_5.png',\n",
    "    'binary_results/pred_6.png',\n",
    "    'binary_results/pred_7.png',\n",
    "    'binary_results/pred_8.png',\n",
    "    'binary_results/pred_9.png',\n",
    "    'binary_results/pred_10.png',\n",
    "    'binary_results/pred_11.png',\n",
    "    'binary_results/pred_12.png',\n",
    "    'binary_results/pred_13.png',\n",
    "    'binary_results/pred_14.png',\n",
    "    'binary_results/pred_15.png',\n",
    "]\n",
    "\n",
    "TRAIN_IMG_DIR = \"../../CoastSat/data/blackpool/images/binary_train/\"\n",
    "TRAIN_MASK_DIR = \"../../CoastSat/data/blackpool/images/binary_trainannot/\"\n",
    "TEST_IMG_DIR = \"../../CoastSat/data/blackpool/images/binary_test/\"\n",
    "TEST_MASK_DIR = \"../../CoastSat/data/blackpool/images/binary_testannot/\"\n",
    "# VAL_IMG_DIR = '../../CoastSat/data/blackpool/images/val/'\n",
    "# VAL_MASK_DIR = '../../CoastSat/data/blackpool/images/valannot/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log parameters to neptune\n",
    "run['parameters/model/model_name'].log(MODEL_NAME)\n",
    "run['parameters/model/encoder'].log(ENCODER)\n",
    "run['parameters/model/encoder_weights'].log(ENCODER_WEIGHTS)\n",
    "run['parameters/model/activation'].log(ACTIVATION)\n",
    "run['parameters/model/batch_size'].log(BATCH_SIZE)\n",
    "run['parameters/model/learning_rate'].log(LEARNING_RATE)\n",
    "run['parameters/model/loss'].log(LOSS_STR)\n",
    "run['parameters/model/device'].log(DEVICE)\n",
    "run['parameters/optimizer/optimizer_name'].log(OPTIM_NAME)\n",
    "run['parameters/optimizer/beta1'].log(BETA1)\n",
    "run['parameters/optimizer/beta2'].log(BETA2)\n",
    "run['parameters/optimizer/epsilon'].log(EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"This method creates the dataset from given directories\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        \"\"\"initialize directories\n",
    "        :image_dir: TODO\n",
    "        :mask_dir: TODO\n",
    "        :transform: TODO\n",
    "        \"\"\"\n",
    "        self._image_dir = image_dir\n",
    "        self._mask_dir = mask_dir\n",
    "        self._transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns length of images\n",
    "        :returns: TODO\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"TODO: Docstring for __getitem__.\n",
    "        :returns: TODO\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self._image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self._mask_dir, self.images[index])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        mask[mask == 255.0] = 1\n",
    "\n",
    "        if self._transform is not None:\n",
    "            augmentations = self._transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_mask_dir,\n",
    "    val_dir,\n",
    "    val_mask_dir,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    This method creates the dataloader objects for the training loops\n",
    "\n",
    "    :train_dir: directory of training images\n",
    "    :train_mask_dir: directory of training masks\n",
    "    :val_dir: validation image directory\n",
    "\n",
    "    :returns: training and validation dataloaders\n",
    "    recall\n",
    "    \"\"\"\n",
    "    train_ds = Dataset(train_dir,\n",
    "        train_mask_dir,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = Dataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(height=TRAIN_MIN_HEIGHT, width=TRAIN_MIN_WIDTH),\n",
    "    A.Rotate(limit=35, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "    A.Downscale(scale_min=0.25, scale_max=0.25, interpolation=0, always_apply=False, p=0.5),\n",
    "    A.Emboss(alpha=(0.2, 0.5), strength=(0.2, 0.7), always_apply=False, p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "], )\n",
    "\n",
    "test_transform = A.Compose([\n",
    "        A.Resize(MIN_HEIGHT, MIN_WIDTH),\n",
    "        ToTensorV2(),\n",
    "    ], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataloaders\n",
    "trainDL, testDL = get_loaders(TRAIN_IMG_DIR, TRAIN_MASK_DIR,\n",
    "                                           TEST_IMG_DIR, TEST_MASK_DIR,\n",
    "                                           BATCH_SIZE, train_transform,\n",
    "                                           test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = smp.Unet(\n",
    "   encoder_name=ENCODER, \n",
    "   encoder_weights=ENCODER_WEIGHTS, \n",
    "   in_channels=3,\n",
    "   classes=1,\n",
    "   activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "# wavelet_model = UNET(in_channels=3, out_channels=6).to(DEVICE)\n",
    "\n",
    "# metrics have been defined in the custom training loop as giving them in a list object did not work for me\n",
    "\n",
    "\n",
    "# define optimizer and learning rate\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2), eps=EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "    smp.utils.metrics.Precision(threshold=0.5),\n",
    "    smp.utils.metrics.Recall(threshold=0.5),\n",
    "    smp.utils.metrics.Fscore(threshold=0.5),\n",
    "]\n",
    "\n",
    "def check_accuracy(metrics, loader, model, device='cpu'):\n",
    "    \"\"\" Custom method to calculate accuracy of testing data\n",
    "    :loader: dataloader objects\n",
    "    :model: model to test\n",
    "    :device: cpu or gpu\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval() # set model for evaluation\n",
    "    metrics_meters = {metric.__name__: AverageValueMeter() for metric in metrics}\n",
    "    with torch.no_grad():  # do not calculate gradients\n",
    "        for x, y in loader:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).unsqueeze(1)\n",
    "            #x = x.permute(0,1,3,2)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            \n",
    "            for metric_fn in metrics:\n",
    "                    metric_value = metric_fn(preds, y).cpu().detach().numpy()\n",
    "                    metrics_meters[metric_fn.__name__].add(metric_value)\n",
    "            \n",
    "            metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n",
    "            \n",
    "    print(metrics_logs)\n",
    "    #print([type(k) for k in metrics_logs.values()])\n",
    "    \n",
    "    # log metrics into neptune\n",
    "    run['metrics/train/iou_score'].log(metrics_logs['iou_score'])\n",
    "    run['metrics/train/f1_score'].log(metrics_logs['fscore'])\n",
    "    run['metrics/train/precision'].log(metrics_logs['precision'])\n",
    "    run['metrics/train/recall'].log(metrics_logs['recall'])\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "def save_predictions_as_imgs(loader,\n",
    "                             model,\n",
    "                             folder=\"binary_results/\",\n",
    "                             device='cpu',\n",
    "                             ):\n",
    "    \"\"\"TODO: Docstring for save_predictions_as_imgs.\n",
    "    :loader: TODO\n",
    "    :model: TODO\n",
    "    :folder: TODO\n",
    "    :device: TODO\n",
    "    :returns: TODO\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device=device).float()\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_wavelet(loader, model, optimizer, loss_fn, scaler):\n",
    "    \"\"\"TODO: Docstring for train_fn.\n",
    "\n",
    "    :loader: TODO\n",
    "    :model: TODO\n",
    "    :optimizer: TODO\n",
    "    :loss_fn: TODO\n",
    "    :scaler: TODO\n",
    "    :returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE).float()\n",
    "        targets = targets.to(device=DEVICE)\n",
    "        targets = targets.long()\n",
    "        data = data.permute(0,3,1,2)  # correct shape for image\n",
    "        targets = targets.squeeze(1)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data.contiguous())\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "#     \"\"\" Custom training loop for models\n",
    "\n",
    "#     :loader: dataloader object\n",
    "#     :model: model to train\n",
    "#     :optimizer: training optimizer\n",
    "#     :loss_fn: loss function\n",
    "#     :scaler: scaler object\n",
    "#     :returns:\n",
    "\n",
    "#     \"\"\"\n",
    "#     loop = tqdm(loader)  # just a nice library to keep track of loops\n",
    "#     model = model.to(DEVICE)# ===========================================================================\n",
    "#     for batch_idx, (data, targets) in enumerate(loop):  # iterate through dataset\n",
    "#         data = data.to(device=DEVICE).float()\n",
    "#         targets = targets.to(device=DEVICE).float()\n",
    "#         targets = targets.unsqueeze(1)\n",
    "#         data = data.permute(0,3,2,1)  # correct shape for image# ===========================================================================\n",
    "#         targets = targets.to(torch.int64)\n",
    "\n",
    "#         # forward\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             predictions = model(data)\n",
    "#             loss = loss_fn(predictions, targets)\n",
    "\n",
    "#         # backward\n",
    "#         optimizer.zero_grad()\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "#         # loss_values.append(loss.item())\n",
    "#         #run['training/batch/loss'].log(loss)\n",
    "\n",
    "#         #update loop\n",
    "#         loop.set_postfix(loss=loss.item())\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    \"\"\"TODO: Docstring for train_fn.\n",
    "    :loader: TODO\n",
    "    :model: TODO\n",
    "    :optimizer: TODO\n",
    "    :loss_fn: TODO\n",
    "    :scaler: TODO\n",
    "    :returns: TODO\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE).float()\n",
    "        targets = targets.unsqueeze(1).to(device=DEVICE).float()\n",
    "        #data = data.permute(0,1,3,2)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "\n",
    "        run['metrics/train/loss'].log(loss.item())\n",
    "        # update loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "for epoch in range(EPOCHS):  # run training and accuracy functions and save model\n",
    "    run['parameters/epochs'].log(epoch)\n",
    "    train_fn(trainDL, model, optimizer, loss, scaler)\n",
    "    #train_wavelet(trainDL, wavelet_model, optimizer, loss, scaler)\n",
    "    check_accuracy(metrics, testDL, model, DEVICE)\n",
    "    save_predictions_as_imgs(\n",
    "        testDL,\n",
    "        model,\n",
    "        folder='./binary_results/',\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    torch.save(model, './binary_{}.pth'.format(MODEL_NAME))\n",
    "    scheduler.step()\n",
    "    \n",
    "    # if epoch in {25, 50 ,75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400}:\n",
    "    #     run[\"model_checkpoints/{}\".format(MODEL_NAME)].upload(\"./binary_{}.pth\".format(MODEL_NAME))\n",
    "\n",
    "    # if epoch in {100, 200, 300, 400}:\n",
    "    #     for image_path in binary_result_paths:\n",
    "    #             run[\"train/results\"].log(File(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Files and directories in a specified path:\")\n",
    "xcd = 0\n",
    "for filename in os.listdir(TEST_MASK_DIR):\n",
    "    f = os.path.join(TEST_MASK_DIR,filename)\n",
    "    if os.path.isfile(f):\n",
    "        im_gray = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        (thresh, im_bw) = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        cv2.imwrite(f, im_bw)\n",
    "        xcd+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a7cb2997f409818a2f560ca2b7e2dddd818ab4252eb1067f63da94cd1a1f870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('lambda-stack-with-tensorflow-pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
