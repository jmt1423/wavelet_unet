{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tvtransforms\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTICLASS_MODE: str = \"multiclass\"\n",
    "ENCODER = \"resnet18\"\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['background', 'ocean', 'wetsand', 'buildings', 'vegetation', 'drysand']\n",
    "ACTIVATION = None\n",
    "BATCH_SIZE = 1\n",
    "DEVICE = 'cuda'\n",
    "TRAIN_IMG_DIR = \"../../CoastSat/data/blackpool/images/train/\"\n",
    "TRAIN_MASK_DIR = \"../../CoastSat/data/blackpool/images/trainannot/\"\n",
    "VAL_IMG_DIR = \"../../CoastSat/data/blackpool/images/val/\"\n",
    "VAL_MASK_DIR = \"../../CoastSat/data/blackpool/images/valannot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail = torch.cuda.is_available()\n",
    "devCnt = torch.cuda.device_count()\n",
    "devName = torch.cuda.get_device_name(0)\n",
    "print(\"Available: \" + str(avail) + \", Count: \" + str(devCnt) + \", Name: \" + str(devName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"This method creates the dataset from given directories\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        \"\"\"initialize directories\n",
    "\n",
    "        :image_dir: TODO\n",
    "        :mask_dir: TODO\n",
    "        :transform: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        self._image_dir = image_dir\n",
    "        self._mask_dir = mask_dir\n",
    "        self._transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "        self.mapping = {(0, 0, 0): 0,\n",
    "                        (0, 0, 255): 1,  # 0 = class 1\n",
    "                        (225, 0, 225): 2,  # 1 = class 2\n",
    "                        (255, 0, 0): 3,  # 2 = class 3\n",
    "                        (255, 225, 225): 4, # 3 = class 4\n",
    "                        (255, 255, 0): 5}  # 4 = class 5\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns length of images\n",
    "        :returns: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def mask_to_class_rgb(self, mask):\n",
    "        #print('----mask->rgb----')\n",
    "        h=20\n",
    "        w=722\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = torch.squeeze(mask)  # remove 1\n",
    "\n",
    "        # check the present values in the mask, 0 and 255 in my case\n",
    "        #print('unique values rgb    ', torch.unique(mask)) \n",
    "        # -> unique values rgb     tensor([  0, 255], dtype=torch.uint8)\n",
    "\n",
    "        class_mask = mask\n",
    "        class_mask = class_mask.permute(2, 0, 1).contiguous()\n",
    "        h, w = class_mask.shape[1], class_mask.shape[2]\n",
    "        mask_out = torch.zeros(h, w, dtype=torch.long)\n",
    "\n",
    "        for k in self.mapping:\n",
    "            idx = (class_mask == torch.tensor(k, dtype=torch.uint8).unsqueeze(1).unsqueeze(2))         \n",
    "            validx = (idx.sum(0) == 3)          \n",
    "            mask_out[validx] = torch.tensor(self.mapping[k], dtype=torch.long)\n",
    "\n",
    "        # check the present values after mapping, in my case 0, 1, 2, 3\n",
    "        #print('unique values mapped ', torch.unique(mask_out))\n",
    "        # -> unique values mapped  tensor([0, 1, 2, 3])\n",
    "       \n",
    "        return mask_out\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"TODO: Docstring for __getitem__.\n",
    "        :returns: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self._image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self._mask_dir, self.images[index])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
    "        mask = self.mask_to_class_rgb(mask).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        if self._transform is not None:\n",
    "            augmentations = self._transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "            #mask = mask.unsqueeze(0)\n",
    "            #image = image.permute(0,3,2,1)\n",
    "        \n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_mask_dir,\n",
    "    val_dir,\n",
    "    val_mask_dir,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    \"\"\"TODO: Docstring for get_loaders.\n",
    "\n",
    "    :train_dir: TODO\n",
    "    :train_mask_dir: TODO\n",
    "    :val_dir: TODO\n",
    "    :: TODO\n",
    "    :returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    train_ds = Dataset(image_dir=train_dir,\n",
    "                             mask_dir=train_mask_dir,\n",
    "                             transform=train_transform)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = Dataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),A.Resize(32, 512),]\n",
    ")\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),\n",
    "        A.Resize(32, 512),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.MedianBlur(blur_limit=3, always_apply=False, p=0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDL, testDL = get_loaders(TRAIN_IMG_DIR, TRAIN_MASK_DIR,\n",
    "                                           VAL_IMG_DIR, VAL_MASK_DIR,\n",
    "                                           BATCH_SIZE, train_transform,\n",
    "                                           test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16,5))\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_delete = A.Compose([\n",
    "        A.PadIfNeeded(32,512),\n",
    "        A.Resize(32, 512),\n",
    "        ToTensorV2(),\n",
    "    ], )\n",
    "dataset = Dataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform=transforms_delete)\n",
    "\n",
    "image, mask = dataset[10] # get some sample\n",
    "\n",
    "#visualize(\n",
    "#    image=image,\n",
    "#    mask=mask.squeeze()\n",
    "#)\n",
    "#mask = mask.unsqueeze(0)\n",
    "print(mask.shape)\n",
    "print(image.shape)\n",
    "unique, counts = np.unique(mask, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(image.shape, image.dtype, type(image), mask.shape, \n",
    "mask.dtype, type(mask), mask.min(), \n",
    "image.max(), mask.min(), mask.max())\n",
    "\n",
    "plt.imshow(image.permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "#mask = mask.unsqueeze(0)\n",
    "#print(mask.shape)\n",
    "\n",
    "print(image.shape, image.dtype, type(image), mask.shape, \n",
    "mask.dtype, type(mask), mask.min(), \n",
    "image.max(), mask.min(), mask.max())\n",
    "\n",
    "print(len(CLASSES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    in_channels=3,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define Loss and Metrics to Monitor (Make sure mode = \"multiclass\") ======================================\n",
    "loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "loss.__name__ = 'Dice_loss'\n",
    "#Will not monitor any metircs other than loss. \n",
    "metrics=[]\n",
    "\n",
    "# Define Optimizer (Adam in this case) and learning rate ============================\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training epock =====================================\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics= metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define testing epoch =====================================\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    \"\"\"TODO: Docstring for train_fn.\n",
    "\n",
    "    :loader: TODO\n",
    "    :model: TODO\n",
    "    :optimizer: TODO\n",
    "    :loss_fn: TODO\n",
    "    :scaler: TODO\n",
    "    :returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE).float()\n",
    "        targets = targets.to(device=DEVICE)\n",
    "        targets = targets.unsqueeze(1)\n",
    "        data = data.permute(0,3,1,2)\n",
    "        targets = targets.to(torch.int64)\n",
    "\n",
    "        #print(data.shape)\n",
    "        #print(targets.shape)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss_values.append(loss.item())\n",
    "        #run['training/batch/loss'].log(loss)\n",
    "\n",
    "        #update loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_fn(trainDL, model, optimizer, loss, scaler)\n",
    "    torch.save(model, './best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 512])\n",
      "torch.Size([1, 3, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "# Predict using saved model\n",
    "val_transform = A.Compose(\n",
    "    [A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),A.Resize(32, 512),ToTensorV2()]\n",
    ")\n",
    "\n",
    "val_image = Image.open('../../CoastSat/data/blackpool/images/val/tile_0-2820.png')\n",
    "#val_image.show()\n",
    "\n",
    "transformed = val_transform(image=np.array(val_image))\n",
    "image_transformed = transformed['image']\n",
    "print(image_transformed.shape)\n",
    "\n",
    "batch_tensor = torch.unsqueeze(image_transformed, 0)\n",
    "print(batch_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./best_model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = model(batch_tensor.to(device=DEVICE).float())\n",
    "\n",
    "preds = torch.argmax(out, dim=1)\n",
    "preds = preds.cpu().detach().permute(1,2,0)\n",
    "preds = preds[:,:,0]\n",
    "\n",
    "print(preds.shape)\n",
    "\n",
    "plt.imshow(preds)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a7cb2997f409818a2f560ca2b7e2dddd818ab4252eb1067f63da94cd1a1f870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('lambda-stack-with-tensorflow-pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
