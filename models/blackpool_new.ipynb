{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tvtransforms\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTICLASS_MODE: str = \"multiclass\"\n",
    "ENCODER = \"resnet18\"\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['background', 'ocean', 'wetsand', 'buildings', 'vegetation', 'drysand']\n",
    "ACTIVATION = None\n",
    "BATCH_SIZE = 1\n",
    "DEVICE = 'cuda'\n",
    "TRAIN_IMG_DIR = \"../../CoastSat/data/blackpool/images/train/\"\n",
    "TRAIN_MASK_DIR = \"../../CoastSat/data/blackpool/images/trainannot/\"\n",
    "VAL_IMG_DIR = \"../../CoastSat/data/blackpool/images/val/\"\n",
    "VAL_MASK_DIR = \"../../CoastSat/data/blackpool/images/valannot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available: True, Count: 1, Name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "avail = torch.cuda.is_available()\n",
    "devCnt = torch.cuda.device_count()\n",
    "devName = torch.cuda.get_device_name(0)\n",
    "print(\"Available: \" + str(avail) + \", Count: \" + str(devCnt) + \", Name: \" + str(devName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"This method creates the dataset from given directories\"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        \"\"\"initialize directories\n",
    "\n",
    "        :image_dir: TODO\n",
    "        :mask_dir: TODO\n",
    "        :transform: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        self._image_dir = image_dir\n",
    "        self._mask_dir = mask_dir\n",
    "        self._transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "        self.mapping = {(0, 0, 0): 0,\n",
    "                        (0, 0, 255): 1,  # 0 = class 1\n",
    "                        (225, 0, 225): 2,  # 1 = class 2\n",
    "                        (255, 0, 0): 3,  # 2 = class 3\n",
    "                        (255, 225, 225): 4, # 3 = class 4\n",
    "                        (255, 255, 0): 5}  # 4 = class 5\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns length of images\n",
    "        :returns: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def mask_to_class_rgb(self, mask):\n",
    "        #print('----mask->rgb----')\n",
    "        h=20\n",
    "        w=722\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = torch.squeeze(mask)  # remove 1\n",
    "\n",
    "        # check the present values in the mask, 0 and 255 in my case\n",
    "        #print('unique values rgb    ', torch.unique(mask)) \n",
    "        # -> unique values rgb     tensor([  0, 255], dtype=torch.uint8)\n",
    "\n",
    "        class_mask = mask\n",
    "        class_mask = class_mask.permute(2, 0, 1).contiguous()\n",
    "        h, w = class_mask.shape[1], class_mask.shape[2]\n",
    "        mask_out = torch.zeros(h, w, dtype=torch.long)\n",
    "\n",
    "        for k in self.mapping:\n",
    "            idx = (class_mask == torch.tensor(k, dtype=torch.uint8).unsqueeze(1).unsqueeze(2))         \n",
    "            validx = (idx.sum(0) == 3)          \n",
    "            mask_out[validx] = torch.tensor(self.mapping[k], dtype=torch.long)\n",
    "\n",
    "        # check the present values after mapping, in my case 0, 1, 2, 3\n",
    "        #print('unique values mapped ', torch.unique(mask_out))\n",
    "        # -> unique values mapped  tensor([0, 1, 2, 3])\n",
    "       \n",
    "        return mask_out\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"TODO: Docstring for __getitem__.\n",
    "        :returns: TODO\n",
    "\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self._image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self._mask_dir, self.images[index])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
    "        mask = self.mask_to_class_rgb(mask).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        if self._transform is not None:\n",
    "            augmentations = self._transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "            #mask = mask.unsqueeze(0)\n",
    "            #image = image.permute(0,3,2,1)\n",
    "        \n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    train_dir,\n",
    "    train_mask_dir,\n",
    "    val_dir,\n",
    "    val_mask_dir,\n",
    "    batch_size,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "):\n",
    "    \"\"\"TODO: Docstring for get_loaders.\n",
    "\n",
    "    :train_dir: TODO\n",
    "    :train_mask_dir: TODO\n",
    "    :val_dir: TODO\n",
    "    :: TODO\n",
    "    :returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    train_ds = Dataset(image_dir=train_dir,\n",
    "                             mask_dir=train_mask_dir,\n",
    "                             transform=train_transform)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = Dataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = A.Compose(\n",
    "    [A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),A.Resize(32, 512),]\n",
    ")\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),\n",
    "        A.Resize(32, 512),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.MedianBlur(blur_limit=3, always_apply=False, p=0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDL, testDL = get_loaders(TRAIN_IMG_DIR, TRAIN_MASK_DIR,\n",
    "                                           VAL_IMG_DIR, VAL_MASK_DIR,\n",
    "                                           BATCH_SIZE, train_transform,\n",
    "                                           test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16,5))\n",
    "\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "torch.Size([3, 32, 512])\n",
      "{1: 10521, 2: 512, 3: 1274, 4: 3297, 5: 780}\n",
      "torch.Size([3, 32, 512]) torch.uint8 <class 'torch.Tensor'> torch.Size([32, 512]) torch.int32 <class 'torch.Tensor'> tensor(1, dtype=torch.int32) tensor(255, dtype=torch.uint8) tensor(1, dtype=torch.int32) tensor(5, dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 512]) torch.uint8 <class 'torch.Tensor'> torch.Size([32, 512]) torch.int32 <class 'torch.Tensor'> tensor(1, dtype=torch.int32) tensor(255, dtype=torch.uint8) tensor(1, dtype=torch.int32) tensor(5, dtype=torch.int32)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "transforms_delete = A.Compose([\n",
    "        A.PadIfNeeded(32,512),\n",
    "        A.Resize(32, 512),\n",
    "        ToTensorV2(),\n",
    "    ], )\n",
    "dataset = Dataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform=transforms_delete)\n",
    "\n",
    "image, mask = dataset[10] # get some sample\n",
    "\n",
    "#visualize(\n",
    "#    image=image,\n",
    "#    mask=mask.squeeze()\n",
    "#)\n",
    "#mask = mask.unsqueeze(0)\n",
    "print(mask.shape)\n",
    "print(image.shape)\n",
    "unique, counts = np.unique(mask, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "print(image.shape, image.dtype, type(image), mask.shape, \n",
    "mask.dtype, type(mask), mask.min(), \n",
    "image.max(), mask.min(), mask.max())\n",
    "\n",
    "plt.imshow(image.permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "\n",
    "#mask = mask.unsqueeze(0)\n",
    "#print(mask.shape)\n",
    "\n",
    "print(image.shape, image.dtype, type(image), mask.shape, \n",
    "mask.dtype, type(mask), mask.min(), \n",
    "image.max(), mask.min(), mask.max())\n",
    "\n",
    "print(len(CLASSES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    in_channels=3,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define Loss and Metrics to Monitor (Make sure mode = \"multiclass\") ======================================\n",
    "loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
    "loss.__name__ = 'Dice_loss'\n",
    "#Will not monitor any metircs other than loss. \n",
    "metrics=[]\n",
    "\n",
    "# Define Optimizer (Adam in this case) and learning rate ============================\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training epock =====================================\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics= metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define testing epoch =====================================\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:04<00:00, 30.36it/s, loss=0.309]\n",
      "100%|██████████| 130/130 [00:03<00:00, 38.16it/s, loss=0.292]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.57it/s, loss=0.293] \n",
      "100%|██████████| 130/130 [00:03<00:00, 37.30it/s, loss=0.128] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.83it/s, loss=0.116] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.08it/s, loss=0.133] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.00it/s, loss=0.107] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.27it/s, loss=0.136] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.11it/s, loss=0.0866]\n",
      "100%|██████████| 130/130 [00:03<00:00, 38.03it/s, loss=0.129] \n",
      "100%|██████████| 130/130 [00:03<00:00, 37.67it/s, loss=0.0519]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.55it/s, loss=0.065] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.13it/s, loss=0.0557]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.87it/s, loss=0.0557]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.94it/s, loss=0.0863]\n",
      "100%|██████████| 130/130 [00:03<00:00, 38.11it/s, loss=0.0256]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.67it/s, loss=0.0624]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.62it/s, loss=0.136] \n",
      "100%|██████████| 130/130 [00:03<00:00, 38.13it/s, loss=0.104] \n",
      "100%|██████████| 130/130 [00:03<00:00, 39.62it/s, loss=0.0324]\n",
      "100%|██████████| 130/130 [00:03<00:00, 39.31it/s, loss=0.0832]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0315]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.75it/s, loss=0.04]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 37.55it/s, loss=0.0789]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.77it/s, loss=0.0473]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.44it/s, loss=0.0649]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.55it/s, loss=0.0545]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.52it/s, loss=0.0304]\n",
      "100%|██████████| 130/130 [00:03<00:00, 37.52it/s, loss=0.0441]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.15it/s, loss=0.0548]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.53it/s, loss=0.102] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.78it/s, loss=0.105] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.85it/s, loss=0.0525]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.82it/s, loss=0.0771]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.86it/s, loss=0.07]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.64it/s, loss=0.0352]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.66it/s, loss=0.064] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.69it/s, loss=0.0636]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.72it/s, loss=0.044] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.65it/s, loss=0.0687]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.0523]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.0376]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.46it/s, loss=0.0445]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.69it/s, loss=0.0684]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.54it/s, loss=0.036] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.42it/s, loss=0.075] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.53it/s, loss=0.0352]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.91it/s, loss=0.0354]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.46it/s, loss=0.0672]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.65it/s, loss=0.0733]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.69it/s, loss=0.0471]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.86it/s, loss=0.0415]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.95it/s, loss=0.0359]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.16it/s, loss=0.0556]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.63it/s, loss=0.023] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.54it/s, loss=0.0221]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.83it/s, loss=0.0483]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.87it/s, loss=0.0878]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.85it/s, loss=0.0207]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.73it/s, loss=0.0327]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.50it/s, loss=0.0354]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.66it/s, loss=0.0346]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.57it/s, loss=0.0577]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.61it/s, loss=0.0573]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.84it/s, loss=0.0222]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.74it/s, loss=0.0394]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.0384]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.70it/s, loss=0.043] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.52it/s, loss=0.0481]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.82it/s, loss=0.0367]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0695]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.42it/s, loss=0.0413]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.67it/s, loss=0.0501]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0439]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.44it/s, loss=0.0174]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0312]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.57it/s, loss=0.0377]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.63it/s, loss=0.0217]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.033] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.36it/s, loss=0.0282]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.49it/s, loss=0.0338]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.98it/s, loss=0.0246]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.71it/s, loss=0.0574]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.46it/s, loss=0.0394] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.56it/s, loss=0.0397] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.70it/s, loss=0.0123]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.40it/s, loss=0.0591]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.47it/s, loss=0.0332]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.50it/s, loss=0.0353]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.0357]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.90it/s, loss=0.0288]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.58it/s, loss=0.0148] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.0113] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.51it/s, loss=0.0388]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.33it/s, loss=0.0166]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.047]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.75it/s, loss=0.0404] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.75it/s, loss=0.0251] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.68it/s, loss=0.0511] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.81it/s, loss=0.0254] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.48it/s, loss=0.0218]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0318] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.58it/s, loss=0.00698]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.81it/s, loss=0.0179]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.54it/s, loss=0.029]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.85it/s, loss=0.0182] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.58it/s, loss=0.0277]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.56it/s, loss=0.015] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.24it/s, loss=0.0282]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.21it/s, loss=0.0314] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.43it/s, loss=0.0231] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.044]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.55it/s, loss=0.018]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.70it/s, loss=0.0107]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.0284] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.78it/s, loss=0.0302] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.89it/s, loss=0.0129] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.83it/s, loss=0.0192] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.82it/s, loss=0.0183]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.53it/s, loss=0.0428] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.53it/s, loss=0.0168] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.73it/s, loss=0.024]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.79it/s, loss=0.0193] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.83it/s, loss=0.0477] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.53it/s, loss=0.0348] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.0156] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0198] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.69it/s, loss=0.0306] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.59it/s, loss=0.0381] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.81it/s, loss=0.0123] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.77it/s, loss=0.025]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.79it/s, loss=0.0148] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.76it/s, loss=0.0141] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.44it/s, loss=0.0227] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.37it/s, loss=0.0296] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.57it/s, loss=0.0181] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.89it/s, loss=0.0141] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.65it/s, loss=0.0414]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.66it/s, loss=0.0189] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.63it/s, loss=0.0211] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.69it/s, loss=0.0229] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.16it/s, loss=0.0207] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.74it/s, loss=0.0128] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.93it/s, loss=0.0293] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.75it/s, loss=0.0172] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.41it/s, loss=0.0326] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.85it/s, loss=0.00891]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.81it/s, loss=0.00966]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.30it/s, loss=0.0152] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.45it/s, loss=0.0155] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.71it/s, loss=0.0263]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0107]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.30it/s, loss=0.024]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.77it/s, loss=0.0297] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.58it/s, loss=0.0246] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.60it/s, loss=0.0237] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.79it/s, loss=0.0266] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.66it/s, loss=0.0227] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.68it/s, loss=0.0194] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.82it/s, loss=0.0234] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.73it/s, loss=0.0288] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.82it/s, loss=0.0229] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.67it/s, loss=0.0143] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.56it/s, loss=0.0243] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.46it/s, loss=0.0238] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.85it/s, loss=0.0295] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.49it/s, loss=0.012]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.76it/s, loss=0.0187] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.74it/s, loss=0.0156] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.62it/s, loss=0.012]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.51it/s, loss=0.0129] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.10it/s, loss=0.0365] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.99it/s, loss=0.0359] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.05it/s, loss=0.018]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.08it/s, loss=0.0162] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.15it/s, loss=0.0397] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.97it/s, loss=0.0253] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.83it/s, loss=0.0152] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.04it/s, loss=0.00921]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.11it/s, loss=0.0119] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.96it/s, loss=0.00765]\n",
      "100%|██████████| 130/130 [00:03<00:00, 34.89it/s, loss=0.0237] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.21it/s, loss=0.0119] \n",
      "100%|██████████| 130/130 [00:03<00:00, 36.06it/s, loss=0.0155] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.98it/s, loss=0.017]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.72it/s, loss=0.025]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.96it/s, loss=0.0184] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.95it/s, loss=0.00713]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.84it/s, loss=0.018]  \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.86it/s, loss=0.0249] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.11it/s, loss=0.0123] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.98it/s, loss=0.00345]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.90it/s, loss=0.00573]\n",
      "100%|██████████| 130/130 [00:03<00:00, 36.01it/s, loss=0.0178] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.90it/s, loss=0.0307] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.78it/s, loss=0.0121] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.96it/s, loss=0.0211] \n",
      "100%|██████████| 130/130 [00:03<00:00, 34.86it/s, loss=0.0349] \n",
      "100%|██████████| 130/130 [00:03<00:00, 35.92it/s, loss=0.00999]\n",
      "100%|██████████| 130/130 [00:03<00:00, 35.72it/s, loss=0.0112]\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    \"\"\"TODO: Docstring for train_fn.\n",
    "\n",
    "    :loader: TODO\n",
    "    :model: TODO\n",
    "    :optimizer: TODO\n",
    "    :loss_fn: TODO\n",
    "    :scaler: TODO\n",
    "    :returns: TODO\n",
    "\n",
    "    \"\"\"\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE).float()\n",
    "        targets = targets.to(device=DEVICE)\n",
    "        targets = targets.unsqueeze(1)\n",
    "        data = data.permute(0,3,1,2)\n",
    "        targets = targets.to(torch.int64)\n",
    "\n",
    "        #print(data.shape)\n",
    "        #print(targets.shape)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss_values.append(loss.item())\n",
    "        #run['training/batch/loss'].log(loss)\n",
    "\n",
    "        #update loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_fn(trainDL, model, optimizer, loss, scaler)\n",
    "    torch.save(model, './best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 512])\n",
      "torch.Size([1, 3, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "# Predict using saved model\n",
    "val_transform = A.Compose(\n",
    "    [A.PadIfNeeded(min_height=32, min_width=512, border_mode=4),A.Resize(32, 512),ToTensorV2()]\n",
    ")\n",
    "\n",
    "val_image = Image.open('../../CoastSat/data/blackpool/images/val/tile_0-2820.png')\n",
    "#val_image.show()\n",
    "\n",
    "transformed = val_transform(image=np.array(val_image))\n",
    "image_transformed = transformed['image']\n",
    "print(image_transformed.shape)\n",
    "\n",
    "batch_tensor = torch.unsqueeze(image_transformed, 0)\n",
    "print(batch_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetPlusPlus(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetPlusPlusDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleDict(\n",
       "      (x_0_0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_1_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_2_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_3_3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (x_0_4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./best_model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = model(batch_tensor.to(device=DEVICE).float())\n",
    "\n",
    "preds = torch.argmax(out, dim=1)\n",
    "preds = preds.cpu().detach().permute(1,2,0)\n",
    "preds = preds[:,:,0]\n",
    "\n",
    "print(preds.shape)\n",
    "\n",
    "plt.imshow(preds)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a7cb2997f409818a2f560ca2b7e2dddd818ab4252eb1067f63da94cd1a1f870"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('lambda-stack-with-tensorflow-pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
